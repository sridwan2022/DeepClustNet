## DeepClustNet Implementation

![image](https://github.com/user-attachments/assets/15bfbb9f-338d-4d25-ac14-f4374ffa762d)

The original input features ($x$) are passed through layers of a neural network known as Encoder. The encoder transform the input features from their high dimensional space into a more compacted lower dimension referred to as latent features ($z$). These latent features can be trained to reconstruct the original input features and can equally be mapped into corresponding clusters based on their relative similarities to different clusters’ centroids (μ_k). This architecture is designed to jointly train ($L_{joint}  = L_r  + 〖λL〗_c$) on the reconstructive and discriminative efficiencies of the latent representations in a gradual self-paced learning framework where a student classifier is used to sample easier examples for the training, before the harder ones. The parameters, β_1,β_2 regularize the weight vectors W of the samples to determine their easiness and diversity respectively.
